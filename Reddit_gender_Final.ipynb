{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d87c202",
   "metadata": {},
   "source": [
    "# Data Mining - Kaggle Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c99de7",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "972670fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['test', 'clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# for NLP\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "\n",
    "import sys\n",
    "sys.path+=['src']\n",
    "import data_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97560f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa460b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct training data\n",
    "folder = 'data/train/'\n",
    "datafile = folder+'train_data.csv'\n",
    "data_preprocess.merge_csv(folder, datafile)\n",
    "\n",
    "# Reconstruct Test data\n",
    "folder = 'data/test/'\n",
    "datafile = folder+'test_data.csv'\n",
    "data_preprocess.merge_csv(folder, datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da459a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train/train_data.csv\", encoding=\"utf8\")\n",
    "\n",
    "\n",
    "target = pd.read_csv(\"data/train/train_target.csv\")\n",
    "#target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ceabed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shamus_Aran</td>\n",
       "      <td>mylittlepony</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I don't think we'd get nearly as much fanficti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riddance</td>\n",
       "      <td>sex</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Thanks. I made it up, that's how I got over my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Secret_Wizard</td>\n",
       "      <td>DragonsDogma</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Are you sure you aren't confusing Cyclops (the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penultimatum</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>dont do this to me bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-SE7EN-7</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>That's what we do when we can't find a mate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author          subreddit   created_utc  \\\n",
       "0    Shamus_Aran       mylittlepony  1.388534e+09   \n",
       "1       Riddance                sex  1.388534e+09   \n",
       "2  Secret_Wizard       DragonsDogma  1.388534e+09   \n",
       "3   Penultimatum  malefashionadvice  1.388534e+09   \n",
       "4      7-SE7EN-7      todayilearned  1.388534e+09   \n",
       "\n",
       "                                                body  \n",
       "0  I don't think we'd get nearly as much fanficti...  \n",
       "1  Thanks. I made it up, that's how I got over my...  \n",
       "2  Are you sure you aren't confusing Cyclops (the...  \n",
       "3                             dont do this to me bro  \n",
       "4        That's what we do when we can't find a mate  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1a26b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RedThunder90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lirkmor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In0chi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ProjectGrudge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TehTurtleHermit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  gender\n",
       "0     RedThunder90       0\n",
       "1          Lirkmor       1\n",
       "2           In0chi       0\n",
       "3    ProjectGrudge       0\n",
       "4  TehTurtleHermit       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd6380",
   "metadata": {},
   "source": [
    "How many rows does the training set have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec596964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296042"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60704c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c44841",
   "metadata": {},
   "source": [
    "Checking if there are more comments from the same people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "512808df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='author'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.groupby('author').count().plot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d0ec5b",
   "metadata": {},
   "source": [
    "Checking how many different users wrote comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72e7e92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['author'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e730b3",
   "metadata": {},
   "source": [
    "One user is ubiquitous, in order to remove bias in the model that user's posts are reduced to the mean value of the comments per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e83ef517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.208400</td>\n",
       "      <td>59.208400</td>\n",
       "      <td>59.208400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>298.134567</td>\n",
       "      <td>298.134567</td>\n",
       "      <td>298.134567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19534.000000</td>\n",
       "      <td>19534.000000</td>\n",
       "      <td>19534.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit   created_utc          body\n",
       "count   5000.000000   5000.000000   5000.000000\n",
       "mean      59.208400     59.208400     59.208400\n",
       "std      298.134567    298.134567    298.134567\n",
       "min        1.000000      1.000000      1.000000\n",
       "25%        5.000000      5.000000      5.000000\n",
       "50%       16.000000     16.000000     16.000000\n",
       "75%       54.000000     54.000000     54.000000\n",
       "max    19534.000000  19534.000000  19534.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('author').count().describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4228b98",
   "metadata": {},
   "source": [
    "Adding a count column, initialized at 1 for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28f9b65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shamus_Aran</td>\n",
       "      <td>mylittlepony</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I don't think we'd get nearly as much fanficti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riddance</td>\n",
       "      <td>sex</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Thanks. I made it up, that's how I got over my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Secret_Wizard</td>\n",
       "      <td>DragonsDogma</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Are you sure you aren't confusing Cyclops (the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penultimatum</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>dont do this to me bro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-SE7EN-7</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>That's what we do when we can't find a mate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296037</th>\n",
       "      <td>Tashre</td>\n",
       "      <td>FiftyFifty</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>I don't want to play this game anymore :(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296038</th>\n",
       "      <td>someguyfromtheuk</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>Twist: I am your son and staged all of this to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296039</th>\n",
       "      <td>spurscanada</td>\n",
       "      <td>HIMYM</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>I think a lot of people don't like her because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296040</th>\n",
       "      <td>SPAZZEH</td>\n",
       "      <td>politics</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>And the Tea Party must be having strokes right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296041</th>\n",
       "      <td>whslaxattack</td>\n",
       "      <td>WorldofTanks</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>It has a huge ROF boost, so it is pretty much ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296042 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author          subreddit   created_utc  \\\n",
       "0            Shamus_Aran       mylittlepony  1.388534e+09   \n",
       "1               Riddance                sex  1.388534e+09   \n",
       "2          Secret_Wizard       DragonsDogma  1.388534e+09   \n",
       "3           Penultimatum  malefashionadvice  1.388534e+09   \n",
       "4              7-SE7EN-7      todayilearned  1.388534e+09   \n",
       "...                  ...                ...           ...   \n",
       "296037            Tashre         FiftyFifty  1.391213e+09   \n",
       "296038  someguyfromtheuk          AskReddit  1.391213e+09   \n",
       "296039       spurscanada              HIMYM  1.391213e+09   \n",
       "296040           SPAZZEH           politics  1.391213e+09   \n",
       "296041      whslaxattack       WorldofTanks  1.391213e+09   \n",
       "\n",
       "                                                     body  count  \n",
       "0       I don't think we'd get nearly as much fanficti...      1  \n",
       "1       Thanks. I made it up, that's how I got over my...      1  \n",
       "2       Are you sure you aren't confusing Cyclops (the...      1  \n",
       "3                                  dont do this to me bro      1  \n",
       "4             That's what we do when we can't find a mate      1  \n",
       "...                                                   ...    ...  \n",
       "296037          I don't want to play this game anymore :(      1  \n",
       "296038  Twist: I am your son and staged all of this to...      1  \n",
       "296039  I think a lot of people don't like her because...      1  \n",
       "296040  And the Tea Party must be having strokes right...      1  \n",
       "296041  It has a huge ROF boost, so it is pretty much ...      1  \n",
       "\n",
       "[296042 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['count'] = 1\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a305e",
   "metadata": {},
   "source": [
    "Selecting the outlier by grouping by author and filtering for message count over 1k. Only one user has such a high message counter --> morbiusgreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c18a3163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['morbiusgreen'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outlier = train.groupby('author').filter(lambda x: len(x) > 10000)\n",
    "train_outlier['author'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337284d",
   "metadata": {},
   "source": [
    "Creating a table without the outlier, in order to understand what is the real mean number of messages per user. In this way, data from the outlier can be still used without completely dropping it, but normalizing it to the other inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0d0bc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.312663</td>\n",
       "      <td>55.312663</td>\n",
       "      <td>55.312663</td>\n",
       "      <td>55.312663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>114.030563</td>\n",
       "      <td>114.030563</td>\n",
       "      <td>114.030563</td>\n",
       "      <td>114.030563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit  created_utc         body        count\n",
       "count  4999.000000  4999.000000  4999.000000  4999.000000\n",
       "mean     55.312663    55.312663    55.312663    55.312663\n",
       "std     114.030563   114.030563   114.030563   114.030563\n",
       "min       1.000000     1.000000     1.000000     1.000000\n",
       "25%       5.000000     5.000000     5.000000     5.000000\n",
       "50%      16.000000    16.000000    16.000000    16.000000\n",
       "75%      54.000000    54.000000    54.000000    54.000000\n",
       "max    1524.000000  1524.000000  1524.000000  1524.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping from train table the rows with author \"morbiusgreen\". Drop requires index of these rows, so index is provided\n",
    "train_aux = train.drop(train[train.author == 'morbiusgreen'].index)\n",
    "train_aux.groupby('author').count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ade6dc",
   "metadata": {},
   "source": [
    "Morbiusgreen is the outlier with a huge number of posts. Let's remove some of the posts and leave about the mean value of posts per user for Morbiusgreen. \n",
    "\n",
    "Selecting what percentage of messages from outlier to keep (0.2%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ed09c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002815603563018327"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc = 55/19534\n",
    "perc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0147d5",
   "metadata": {},
   "source": [
    "Keeping the 0.2% of messages from outlier and dropping all the other $1-perc$ messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ad9aa23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shamus_Aran</td>\n",
       "      <td>mylittlepony</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I don't think we'd get nearly as much fanficti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riddance</td>\n",
       "      <td>sex</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Thanks. I made it up, that's how I got over my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Secret_Wizard</td>\n",
       "      <td>DragonsDogma</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Are you sure you aren't confusing Cyclops (the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penultimatum</td>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>dont do this to me bro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-SE7EN-7</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>That's what we do when we can't find a mate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296037</th>\n",
       "      <td>Tashre</td>\n",
       "      <td>FiftyFifty</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>I don't want to play this game anymore :(</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296038</th>\n",
       "      <td>someguyfromtheuk</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>Twist: I am your son and staged all of this to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296039</th>\n",
       "      <td>spurscanada</td>\n",
       "      <td>HIMYM</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>I think a lot of people don't like her because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296040</th>\n",
       "      <td>SPAZZEH</td>\n",
       "      <td>politics</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>And the Tea Party must be having strokes right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296041</th>\n",
       "      <td>whslaxattack</td>\n",
       "      <td>WorldofTanks</td>\n",
       "      <td>1.391213e+09</td>\n",
       "      <td>It has a huge ROF boost, so it is pretty much ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276563 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author          subreddit   created_utc  \\\n",
       "0            Shamus_Aran       mylittlepony  1.388534e+09   \n",
       "1               Riddance                sex  1.388534e+09   \n",
       "2          Secret_Wizard       DragonsDogma  1.388534e+09   \n",
       "3           Penultimatum  malefashionadvice  1.388534e+09   \n",
       "4              7-SE7EN-7      todayilearned  1.388534e+09   \n",
       "...                  ...                ...           ...   \n",
       "296037            Tashre         FiftyFifty  1.391213e+09   \n",
       "296038  someguyfromtheuk          AskReddit  1.391213e+09   \n",
       "296039       spurscanada              HIMYM  1.391213e+09   \n",
       "296040           SPAZZEH           politics  1.391213e+09   \n",
       "296041      whslaxattack       WorldofTanks  1.391213e+09   \n",
       "\n",
       "                                                     body  count  \n",
       "0       I don't think we'd get nearly as much fanficti...      1  \n",
       "1       Thanks. I made it up, that's how I got over my...      1  \n",
       "2       Are you sure you aren't confusing Cyclops (the...      1  \n",
       "3                                  dont do this to me bro      1  \n",
       "4             That's what we do when we can't find a mate      1  \n",
       "...                                                   ...    ...  \n",
       "296037          I don't want to play this game anymore :(      1  \n",
       "296038  Twist: I am your son and staged all of this to...      1  \n",
       "296039  I think a lot of people don't like her because...      1  \n",
       "296040  And the Tea Party must be having strokes right...      1  \n",
       "296041  It has a huge ROF boost, so it is pretty much ...      1  \n",
       "\n",
       "[276563 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(train[train.author == 'morbiusgreen'].sample(frac = 1 - perc).index)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa989d",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee9834",
   "metadata": {},
   "source": [
    "Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57f87f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ejchristian86</td>\n",
       "      <td>TwoXChromosomes</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I hadn't ever heard of them before joining thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>gaming</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>At 7680 by 4320 with 64x AA, right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>savoytruffle</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>bite me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hentercenter</td>\n",
       "      <td>stlouisblues</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Damn that was a good penalty :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rick-o-suave</td>\n",
       "      <td>army</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I swore into DEP on 6-OCT and I left 5-NOV und...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author        subreddit   created_utc  \\\n",
       "0  ejchristian86  TwoXChromosomes  1.388534e+09   \n",
       "1      ZenDragon           gaming  1.388534e+09   \n",
       "2   savoytruffle        AskReddit  1.388534e+09   \n",
       "3   hentercenter     stlouisblues  1.388534e+09   \n",
       "4   rick-o-suave             army  1.388534e+09   \n",
       "\n",
       "                                                body  \n",
       "0  I hadn't ever heard of them before joining thi...  \n",
       "1                At 7680 by 4320 with 64x AA, right?  \n",
       "2                                            bite me  \n",
       "3                    Damn that was a good penalty :(  \n",
       "4  I swore into DEP on 6-OCT and I left 5-NOV und...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test/test_data.csv\", encoding=\"utf8\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e66f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107946"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31b7d382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>gaming</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>At 7680 by 4320 with 64x AA, right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27836</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1.388638e+09</td>\n",
       "      <td>Wrong subreddit for this kind of post, but /r/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29348</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>Nexus7</td>\n",
       "      <td>1.388642e+09</td>\n",
       "      <td>This is something GravityBox can do. (a module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55061</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>WTF</td>\n",
       "      <td>1.388722e+09</td>\n",
       "      <td>Why is the enclosure even designed like that? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90435</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>gadgets</td>\n",
       "      <td>1.388845e+09</td>\n",
       "      <td>**Especially** blue ones. They don't instantly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065115</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.391093e+09</td>\n",
       "      <td>I ran into my two exes, Alex and Sarah at Swis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080476</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>KerbalSpaceProgram</td>\n",
       "      <td>1.391128e+09</td>\n",
       "      <td>Does a spacecraft piloted by a cat always land...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083575</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>programming</td>\n",
       "      <td>1.391135e+09</td>\n",
       "      <td>Well, yeah... Lua follows old language standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091883</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.391169e+09</td>\n",
       "      <td>Jesus man I think ten seconds with a damp clot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092326</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>minecraftsuggestions</td>\n",
       "      <td>1.391172e+09</td>\n",
       "      <td>That would get pretty messy as soon as player ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            author             subreddit   created_utc  \\\n",
       "1        ZenDragon                gaming  1.388534e+09   \n",
       "27836    ZenDragon     explainlikeimfive  1.388638e+09   \n",
       "29348    ZenDragon                Nexus7  1.388642e+09   \n",
       "55061    ZenDragon                   WTF  1.388722e+09   \n",
       "90435    ZenDragon               gadgets  1.388845e+09   \n",
       "...            ...                   ...           ...   \n",
       "1065115  ZenDragon             AskReddit  1.391093e+09   \n",
       "1080476  ZenDragon    KerbalSpaceProgram  1.391128e+09   \n",
       "1083575  ZenDragon           programming  1.391135e+09   \n",
       "1091883  ZenDragon             AskReddit  1.391169e+09   \n",
       "1092326  ZenDragon  minecraftsuggestions  1.391172e+09   \n",
       "\n",
       "                                                      body  \n",
       "1                      At 7680 by 4320 with 64x AA, right?  \n",
       "27836    Wrong subreddit for this kind of post, but /r/...  \n",
       "29348    This is something GravityBox can do. (a module...  \n",
       "55061    Why is the enclosure even designed like that? ...  \n",
       "90435    **Especially** blue ones. They don't instantly...  \n",
       "...                                                    ...  \n",
       "1065115  I ran into my two exes, Alex and Sarah at Swis...  \n",
       "1080476  Does a spacecraft piloted by a cat always land...  \n",
       "1083575  Well, yeah... Lua follows old language standar...  \n",
       "1091883  Jesus man I think ten seconds with a damp clot...  \n",
       "1092326  That would get pretty messy as soon as player ...  \n",
       "\n",
       "[69 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.author=='ZenDragon']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8330587",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93707c3",
   "metadata": {},
   "source": [
    "## Reddit subforum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc585b",
   "metadata": {},
   "source": [
    "Mapping each subreddit to a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = train.subreddit.unique()\n",
    "subreddits_map = pd.Series(index=subreddits, data=arange(subreddits.shape[0]))\n",
    "\n",
    "subreddits_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for the subreddit\n",
    "\n",
    "from scipy import sparse\n",
    "def extract_features(group):\n",
    "    group_subreddits = group['subreddit']\n",
    "    group_subreddits = group_subreddits[group_subreddits.isin(subreddits_map.index)].values\n",
    "    idxs = subreddits_map.loc[group_subreddits].values\n",
    "    v = sparse.dok_matrix((1, subreddits.shape[0]))\n",
    "    for idx in idxs:\n",
    "        if not np.isnan(idx):\n",
    "            v[0, idx] = 1\n",
    "    return v.tocsr()\n",
    "\n",
    "\n",
    "extract_features(train[train.author=='RedThunder90'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378939e",
   "metadata": {},
   "source": [
    "Inserting subreddit information in a dictionary, then used to build a matrix X of One-hot-encoded subreddit feature, that will be substituting the subreddit column in the original matrix with multiple, categorical columns in the final design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca69465",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {}\n",
    "test_features_dict = {}\n",
    "\n",
    "for author, group in train.groupby('author'):\n",
    "    features_dict[author] = extract_features(group)\n",
    "\n",
    "for author, group in test.groupby('author'):\n",
    "    test_features_dict[author] = extract_features(group)\n",
    "    \n",
    "test_features_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6247113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subs = sparse.vstack([features_dict[author] for author in target.author])\n",
    "\n",
    "\n",
    "X_subs_test = sparse.vstack([test_features_dict[author] for author in test.author.unique()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbd9aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_subs.npz', X_subs)\n",
    "sparse.save_npz('data/X_subs_test.npz', X_subs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37431a",
   "metadata": {},
   "source": [
    "### Extracting and transforming text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938eef03",
   "metadata": {},
   "source": [
    "Let's now do feature extraction from the text. First of all, we need to put together all the text written by the specific user, in order to analyze it thoroughly.\n",
    "\n",
    "For example, user '-Jared' has written several posts; let's gather all the text in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512074b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['author']=='-Jared']['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "232949cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neil Diamond - Sweet Caroline +1 on the chiropractor. I went religiously from ages 14 - 19 due to extreme lower back pain from running track / cross country. It\\'s important to remember it\\'s a somewhat slow process, but worth the results. \\n\\nOh, and don\\'t worry, they aren\\'t cracking your back - its just an \"adjustment\"  Looks like the pattern on the envelope that middle school photos came in.  If you had a bad motivator would you want to spell that out every time? And nothing beats a hangover quite like bacon (or better yet, Taylor ham), eggs over easy, toast, and hash browns! No, I think YOU mean Taylor Ham... Really, whatever you call it doesn\\'t matter, its damn delicious. '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text(group):\n",
    "    group_text = group['body'].astype(str).values\n",
    "    full_text = \" \".join(group_text)\n",
    "    return full_text\n",
    "\n",
    "extract_text(train[train.author=='-Jared'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513555f",
   "metadata": {},
   "source": [
    "Let's now gather text for each user.\n",
    "\n",
    "Lower-case is applied as well. For Bag-of-Words lower_case will be used, whereas for some of other feature, where capital letters or words are evaluated, the one with upper-cases will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a73e5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base\n",
    "text_dict = {}\n",
    "test_text_dict = {}\n",
    "#Lower case\n",
    "text_dict_lower = {}\n",
    "test_text_dict_lower = {}\n",
    "\n",
    "#Training\n",
    "for author, group in train.groupby('author'):\n",
    "    full_text = extract_text(group)\n",
    "    text_dict[author] = full_text\n",
    "    text_dict_lower[author] = full_text.lower()\n",
    "    \n",
    "author_text = [text_dict[author] for author in target.author]\n",
    "author_text_lower = [text_dict_lower[author] for author in target.author]\n",
    "\n",
    "#Test\n",
    "for author, group in test.groupby('author'):\n",
    "    full_text = extract_text(group)\n",
    "    test_text_dict[author] = full_text\n",
    "    test_text_dict_lower[author] = full_text.lower()\n",
    "\n",
    "test_author_text = [test_text_dict[author] for author in test.author.unique()]\n",
    "test_author_text_lower = [test_text_dict_lower[author] for author in test.author.unique()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ade0856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"darn, someone already used it.  yep, a co-worker showed me this. as soon as i have the money, i'm canceling my account with sprint. drinking tea with local honey will help, somewhat. bees pollinating  everything, those dirty little bees. as someone who has done support for a ton of video game companies:\\n**no.** for kids! i really hate to say, but check out a school system called harmony science academy. i went there from 6th to 12th. one of the requirements of graduation is to get accepted to a 4 year college. they've never had one person not graduate because of it. the teachers all really do care. they are very good with academics, but not so much sports. if you really are looking for a good college prep school, i couldn't recommend a better one. i had an ex give me this. \\nex. famine, disease, introduction to native americans?  oh gosh, the return of the king! it is so much fun to play with friends! ironically, i have that same thing on my desk. who would have thought?\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_text_lower[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e63e0",
   "metadata": {},
   "source": [
    "## LEMMATIZATION/STEMMING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb140413",
   "metadata": {},
   "source": [
    "For Bag of Words, a lemmatized text is provided in order to reduce vocabulary and thus number of features, and at the same time limit sparse words such as \"Hellllooooo\" typical of social media and that are highly unlikely to be present more than once, if ever. This kind of words contain information though, in their meaning. Thus, by applying a lemmatization technique, we are preserving meaning and neglecting the specific modified word.\n",
    "\n",
    "Since we use Pos-Tagging as a guideline for correct lemmatization, we need to map tags used by Pos-Tagging to the tags used by the Lemmatization tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd4922dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be744f70",
   "metadata": {},
   "source": [
    "Then we create a translator to remove punctuation. This is the first of the pipeline, in which we clean data from punctuations in order to isolate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba00ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82069f0",
   "metadata": {},
   "source": [
    "Creating a function that:\n",
    "1) Removes punctuation\n",
    "\n",
    "2) Tokenizes text (subdivides text in a list of words, so called tokens)\n",
    "\n",
    "3) Applies Pos-Tagging, thus giving grammatical context to each one of the tokens\n",
    "\n",
    "4) Applies Lemmatization, reducing each word to their root. The tag is coherently mapped from Pos-Tag to wordnet through the *get_wordnet_pos* function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a2ed59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pos_lemmatizer(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "    data = text.translate(translator)\n",
    "    words=word_tokenize(data)\n",
    "    pos = nltk.pos_tag(words)\n",
    "\n",
    "\n",
    "    lemmatized_sentence = []\n",
    "    for tpl in pos:\n",
    "        tag = get_wordnet_pos(tpl[1])\n",
    "        if tag != '':\n",
    "            lemma = lemmatizer.lemmatize(tpl[0], get_wordnet_pos(tpl[1]))\n",
    "        else: \n",
    "            lemma = lemmatizer.lemmatize(tpl[0])\n",
    "    \n",
    "        lemmatized_sentence.append(lemma)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "\n",
    "#lemmatized_sentence = []\n",
    "#for tpl in pos:\n",
    "#    print(tpl)\n",
    "#    lemma = lemmatizer.lemmatize(tpl[0], tag[1].lower())\n",
    "#    lemmatized_sentence.append(lemma)\n",
    "#words = [lemmmatizer.lemmatize(word[0],word[1]) for word in pos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e590b",
   "metadata": {},
   "source": [
    "Applying Lemmatization to all text data. From this point on, we can apply Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64b09b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_data=[]\n",
    "for author in author_text_lower:\n",
    "    lemma = token_pos_lemmatizer(author)\n",
    "    #Creating one single blob of text by joining the lemmatized words, from the list created by the lemmatizer. \n",
    "    #This way, the lemmatized data can be fed to a TF-IDF Vectorizer which accepts only blob of strings\n",
    "    lemmatized_data.append(\" \".join(lemma))\n",
    "\n",
    "lemmatized_data_test=[]\n",
    "for author in test_author_text_lower:\n",
    "    lemma = token_pos_lemmatizer(author)\n",
    "    #Creating one single blob of text by joining the lemmatized words, from the list created by the lemmatizer. \n",
    "    #This way, the lemmatized data can be fed to a TF-IDF Vectorizer which accepts only blob of strings\n",
    "    lemmatized_data_test.append(\" \".join(lemma))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860d6c1",
   "metadata": {},
   "source": [
    "Now, with this data we apply Bag-of-Words through a TF-IDF Vectorizer. Features are normalized, thus no further normalization is applied. Furthermore, not all features in the Training Data are selected: a threshold of appearence has been put, so that only features that appear in at least 5% of the texts is accepted. This is done in order to remove outliers (noise) and keeping into account the fact that in social media writing style allows for same words written in different formats, which would appear only once in the whole dataset. This does not provide any information regarding writing style of gender, so it is removed. This should help computation time as well as performance.\n",
    "\n",
    "Edit: TF-IDF was initially switched-off, as we are looking for writing style rather than topic/content. After performing some tests, TF-IDF seems to give better performance, hence it was turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc5ddc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15000x3594 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5062855 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm='l2', min_df=0.02)\n",
    "vectorizer.fit(lemmatized_data)\n",
    "X_lembow = vectorizer.transform(lemmatized_data)\n",
    "X_lembow_test = vectorizer.transform(lemmatized_data_test)\n",
    "\n",
    "X_lembow\n",
    "X_lembow_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c3c40",
   "metadata": {},
   "source": [
    "Saving the feature to file, so that features will not have to be extracted every time the notebook is closed. At the end of the feature extraction process, all these feature matrices will be stacked together to form the Design Matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdcad0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_lembow.npz', X_lembow)\n",
    "sparse.save_npz('data/X_lembow_test.npz', X_lembow_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54459df",
   "metadata": {},
   "source": [
    "## Bag of Words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50b05a",
   "metadata": {},
   "source": [
    "Evaluating the frequency of the words used in the posts (augmented frequency, in order to eliminate bias towards lengthier documents). The Inverse Document Frequency is switched off (idf=1) since in this specific case it is not relevant to normalize for frequency in documents, the goal here is to evaluate how and what users write in spite of how many users do use the same words and how frequently. \n",
    "\n",
    "EDIT: IDF enabled as it provides better performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ac38e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm='l2', min_df=0.02)\n",
    "vectorizer.fit(author_text_lower)\n",
    "X_bow = vectorizer.transform(author_text_lower)\n",
    "X_bow_test = vectorizer.transform(test_author_text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names_out()\n",
    "[i for i in features if '' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5eb5e2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x4414 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1895202 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d49a11",
   "metadata": {},
   "source": [
    "Saving the feature to file, so that features will not have to be extracted every time the notebook is closed. At the end of the feature extraction process, all these feature matrices will be stacked together to form the Design Matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64efb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_bow.npz', X_bow)\n",
    "sparse.save_npz('data/X_bow_test.npz', X_bow_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050a6c8",
   "metadata": {},
   "source": [
    "## Evaluations on text (extracting new possibly useful features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc95f12",
   "metadata": {},
   "source": [
    "The features that might be useful in recognizing gender are:\n",
    "* Words used (thus a bag of words might be useful, in colloquial english stop-words could be included as well in order to model writing style)\n",
    "* Average word length --> OK\n",
    "* Longest word length --> OK\n",
    "* Misspelling frequency --> NO (computationally heavy, probably not that informative either)\n",
    "* Profanity frequency --> OK\n",
    "* Capital word frequency --> OK\n",
    "* Capital letter frequency --> OK\n",
    "* Self-reference Frequency --> OK\n",
    "* Internet acronym frequency --> OK\n",
    "* Exclamation point frequency --> OK\n",
    "* Question mark frequency --> OK \n",
    "* Quotation mark frequency  --> OK\n",
    "* Digits frequency --> OK\n",
    "* Punctuation token frequency --> OK\n",
    "* Emoticon token frequency --> OK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19a57b",
   "metadata": {},
   "source": [
    "### Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f71a1b",
   "metadata": {},
   "source": [
    "Creating a splitter/filter that can optionally remove links and punctuation. Optionally it can track single characters as well, as it will be needed for some of the features to be extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79456a",
   "metadata": {},
   "source": [
    "Using Fnmatch to filter through wildcards for whatever kind of hyper-links in posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3b6ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch as fn\n",
    "\n",
    "filtro = ('*www.*', '*http*', '*.html', '*.gif' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454216d",
   "metadata": {},
   "source": [
    "The splitter/filter function itself. \n",
    "\n",
    "Flatten necessary as a workoaround for nested lists that come up when the fn.filter() is applied.\n",
    "\n",
    "After careful observation of the data, it is noticed that links tend to appear in the following format [TEXT]\\(LINK).\n",
    "In order to retain [TEXT] and remove (LINK) via wildcards, the 2 are separated adding a white-space between parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d77eb224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import flatten\n",
    "import string\n",
    "\n",
    "def text_split_filter(sentence, no_links=True, no_punct=True, char=False):\n",
    "    #Pre-processing in order to remove links\n",
    "    sentence = sentence.replace('](', '] (')\n",
    "    \n",
    "    #Splitting sentence into a list of words\n",
    "    words = sentence.split()\n",
    "    \n",
    "    #Removing Links\n",
    "    if no_links == True:\n",
    "        filtered_words = [] #list of words to be filtered out\n",
    "        for pattern in filtro:\n",
    "            filtered_words.append(fn.filter(words, pattern)) #if there's a match with any patterns, add it to the list of filtered out words\n",
    "        filtered_words = flatten(filtered_words)\n",
    "        words2 = [word for word in words if word not in filtered_words] #Selecting only words that were not filtered out\n",
    "    else:\n",
    "        words2 = words #if no filtered out words, just take them all\n",
    "    \n",
    "    \n",
    "    #Removing Punctuation\n",
    "    words_filtered = []\n",
    "    if no_punct == True:\n",
    "        for word in words2: #Consider words that survived filtering process\n",
    "            #\n",
    "            words_filtered.append(''.join(filter(lambda x: x not in string.punctuation, word)))\n",
    "    else: \n",
    "         words_filtered = words2\n",
    "    \n",
    "    #Subdividing sentence into single chars (no spaces included)\n",
    "    #Needed for extracting certain features, set to False by default\n",
    "    if char == True:\n",
    "        chars = []\n",
    "        for word in words_filtered:\n",
    "            letters = [*word]\n",
    "            chars.append(letters)\n",
    "        \n",
    "        return flatten(chars)\n",
    "    \n",
    "    else:   \n",
    "        return words_filtered\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869726a",
   "metadata": {},
   "source": [
    "Now features are extracted both for training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55d8668",
   "metadata": {},
   "source": [
    "### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(sentence):\n",
    "    words = text_split_filter(sentence)\n",
    "    #In case a message is composed by single punctuations chars or links that have been filtered out\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        average = sum(len(word) for word in words) / (len(words))\n",
    "        return average  \n",
    " \n",
    "avg_word_feature = []\n",
    "test_avg_word_feature = []\n",
    "\n",
    "#Evaluating average word length for each author\n",
    "for text in author_text:\n",
    "    wl = avg_word_length(text)\n",
    "    avg_word_feature.append(wl)\n",
    "    \n",
    "for text in test_author_text:\n",
    "    wl = avg_word_length(text)\n",
    "    test_avg_word_feature.append(wl)\n",
    "\n",
    "avg_word_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddce2c4",
   "metadata": {},
   "source": [
    "Making the feature into a sparse matrix, to even it out with all the other features. In this case, this matrix will probably not be a sparse one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5aefe7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(avg_word_feature)\n",
    "X_averagelength = sparse.csr_matrix(arr.reshape((5000,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2c347532",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_avg_word_feature)\n",
    "X_averagelength_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0239f8ef",
   "metadata": {},
   "source": [
    "Applying feature scaling: these numerical features, by nature, have different scales. Thus, they are normalized such that they weigh the same in ML models and there are no preferential features.\n",
    "\n",
    "The MaxAbsScaler is chosen, since we want to keep sparsity as a quality of our dataset, so that if a sample has value 0 for the specific feature, it will remain 0 after scaling is applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4321e283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4999 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_averagelength)\n",
    "X_averagelength = scaler.transform(X_averagelength)\n",
    "X_averagelength_test = scaler.transform(X_averagelength_test)\n",
    "\n",
    "X_averagelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c2281e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_averagelength.npz', X_averagelength)\n",
    "sparse.save_npz('data/X_averagelength_test.npz', X_averagelength_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14415ab7",
   "metadata": {},
   "source": [
    "### Max word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f850ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_word(sentence):\n",
    "    words = text_split_filter(sentence)\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        print(max(words, key=len))\n",
    "        return len(max(words, key=len)) #Evaluating 'len' attribute for each word of the array, then selecting max and returning its length\n",
    "\n",
    "\n",
    "\n",
    "long_word_feature = []\n",
    "for text in author_text:\n",
    "    length = long_word(text)\n",
    "    long_word_feature.append(length)\n",
    "    \n",
    "test_long_word_feature = []\n",
    "for text in test_author_text:\n",
    "    length = long_word(text)\n",
    "    test_long_word_feature.append(length)\n",
    "\n",
    "long_word_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d5f4c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(long_word_feature)\n",
    "X_maxlength = sparse.csr_matrix(arr.reshape((5000,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d14b3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_long_word_feature)\n",
    "X_maxlength_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "9da6c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_maxlength)\n",
    "X_maxlength = scaler.transform(X_maxlength)\n",
    "X_maxlength_test = scaler.transform(X_maxlength_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e2366ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_maxlength.npz', X_maxlength)\n",
    "sparse.save_npz('data/X_maxlength_test.npz', X_maxlength_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216cdf5",
   "metadata": {},
   "source": [
    "### Misspelling Frequency (not used)\n",
    "It takes too long, and the algorithm might not be very accurate. This feature is thus turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7fb3ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob import Word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d1774170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def spell_checker(sentence):\n",
    "#    words = text_split_filter(sentence)\n",
    "#    counter = 0\n",
    "#    for word in words:\n",
    "#        w = Word(word)\n",
    "#        check_word = w.spellcheck()\n",
    "#        if (check_word[0][0] != word):\n",
    "#            counter += 1\n",
    "#    \n",
    "#    return counter\n",
    "#        \n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a782e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#misspelling_feature = []\n",
    "#for text in author_text:\n",
    "#    N = len(text)\n",
    "#    if N==0:\n",
    "#        n_misspell = 0\n",
    "#    else:\n",
    "#        n_misspell = spell_checker(text)/N\n",
    "#    misspelling_feature.append(n_misspell)\n",
    "#\n",
    "#misspelling_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95501cb3",
   "metadata": {},
   "source": [
    "Adding the feature to the feature matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "71a171e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr = np.array(misspelling_feature)\n",
    "#arr = arr.reshape((5000,1))\n",
    "#\n",
    "#X = sparse.hstack([X,arr])\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3751402",
   "metadata": {},
   "source": [
    "### Profanity Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6781f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profanity = pd.read_csv(\"profanity.csv\", encoding=\"utf8\", header=None)\n",
    "df_profanity = df_profanity[0].str.casefold()\n",
    "profanity_1 = [badword for badword in df_profanity]\n",
    "\n",
    "#Since we apply it to text without punctuation (such as '-'), we eliminate punctuation from profanities as well, to match data\n",
    "profanity = []\n",
    "for badword in profanity_1:\n",
    "    profanity.append(''.join(filter(lambda x: x not in string.punctuation, badword)))\n",
    "profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08a71594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profanity_filter(text):\n",
    "    counter = 0\n",
    "    words = text_split_filter(text)\n",
    "    for word in words:\n",
    "        if word in profanity:\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eac983",
   "metadata": {},
   "source": [
    "Using the lower-cased texts, to match the profanities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2aecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_feature = []\n",
    "for text in author_text_lower:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_badwords = 0\n",
    "    else:\n",
    "        n_badwords = profanity_filter(text)/N\n",
    "    profanity_feature.append(n_badwords)\n",
    "    \n",
    "test_profanity_feature = []\n",
    "for text in test_author_text_lower:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_badwords = 0\n",
    "    else:\n",
    "        n_badwords = profanity_filter(text)/N\n",
    "    test_profanity_feature.append(n_badwords)\n",
    "    \n",
    "profanity_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97ec4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(profanity_feature)\n",
    "X_profanity = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8278fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_profanity_feature)\n",
    "X_profanity_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce4264b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_profanity)\n",
    "X_profanity = scaler.transform(X_profanity)\n",
    "X_profanity_test = scaler.transform(X_profanity_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "861fa116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_profanity.npz', X_profanity)\n",
    "sparse.save_npz('data/X_profanity_test.npz', X_profanity_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7af41",
   "metadata": {},
   "source": [
    "### Capital Words Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66182b",
   "metadata": {},
   "source": [
    "Measuring the frequency of FULL CAPITAL words. Only the pronoun \"I\" is taken out of the counting, for obvious reasons. The idea is to isolate a pattern of highlighting certain words that are not normally written in capital letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c6cdcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capital_words_filter(sentence):\n",
    "    words = text_split_filter(sentence)\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        if word != \"I\":\n",
    "            capital_bool = word.isupper()\n",
    "            if capital_bool == True:\n",
    "                counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e716131",
   "metadata": {},
   "source": [
    "Obviously, the non-lowered-cased text is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_words_feature = []\n",
    "\n",
    "for text in author_text:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        capital_words = 0\n",
    "    else:\n",
    "        capital_words = capital_words_filter(text)/N\n",
    "    capital_words_feature.append(capital_words)\n",
    "\n",
    "test_capital_words_feature = []\n",
    "\n",
    "for text in test_author_text:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        capital_words = 0\n",
    "    else:\n",
    "        capital_words = capital_words_filter(text)/N\n",
    "    test_capital_words_feature.append(capital_words)\n",
    "    \n",
    "capital_words_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c07578b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(capital_words_feature)\n",
    "X_capitalwords = sparse.csr_matrix(arr.reshape((5000,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eb40cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_capital_words_feature)\n",
    "X_capitalwords_test = sparse.csr_matrix(test_arr.reshape((15000,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8df8ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_capitalwords)\n",
    "X_capitalwords = scaler.transform(X_capitalwords)\n",
    "X_capitalwords_test = scaler.transform(X_capitalwords_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a79f06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_capitalwords.npz', X_capitalwords)\n",
    "sparse.save_npz('data/X_capitalwords_test.npz', X_capitalwords_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93405ae5",
   "metadata": {},
   "source": [
    "### Capital Letters Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d447c93",
   "metadata": {},
   "source": [
    "Extrapolate tendencies to use capital letters in words in both appropriate (eg. after a full-stop) or inappropriate (eg. \"she is Going over There\") contexts. THis tendencies may be correlated with gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "90fa4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def capital_letter_filter(sentence):\n",
    "    words = text_split_filter(sentence)\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        if word != \"I\":\n",
    "            capital_counter = len(re.findall('([A-Z])', word))\n",
    "            counter += capital_counter\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f314fd7",
   "metadata": {},
   "source": [
    "Obviously, the non-lowered-cased text is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_letter_feature = []\n",
    "for text in author_text:\n",
    "    words = text_split_filter(text)\n",
    "    N = sum(len(word) for word in words)\n",
    "    \n",
    "    if N == 0:\n",
    "        capital_letter = 0\n",
    "    else:\n",
    "        capital_letter = capital_letter_filter(text)/N\n",
    "    \n",
    "    capital_letter_feature.append(capital_letter)\n",
    "    \n",
    "\n",
    "test_capital_letter_feature = []\n",
    "for text in test_author_text:\n",
    "    words = text_split_filter(text)\n",
    "    N = sum(len(word) for word in words)\n",
    "    \n",
    "    if N == 0:\n",
    "        capital_letter = 0\n",
    "    else:\n",
    "        capital_letter = capital_letter_filter(text)/N\n",
    "    \n",
    "    test_capital_letter_feature.append(capital_letter)\n",
    "    \n",
    "capital_letter_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6489b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(capital_letter_feature)\n",
    "X_capitalletters = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ea5f5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_capital_letter_feature)\n",
    "X_capitalletters_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5ad9c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_capitalletters)\n",
    "X_capitalletters = scaler.transform(X_capitalletters)\n",
    "X_capitalletters_test = scaler.transform(X_capitalletters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0ac73bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_capitalletters.npz', X_capitalletters)\n",
    "sparse.save_npz('data/X_capitalletters_test.npz', X_capitalletters_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f61de53",
   "metadata": {},
   "source": [
    "### Self-reference Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8f27f",
   "metadata": {},
   "source": [
    "Evaluating how frequently a user self-references. the key words for this are the ones contained in the \"self_dict\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "09057f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_dict = [\n",
    "'i',\n",
    "'i\\'m',\n",
    "'im'\n",
    "'myself',\n",
    "'me'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9154b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_reference_filter(text):\n",
    "    words = text_split_filter(text)\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        if word in self_dict:\n",
    "            counter += 1\n",
    "        \n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6351fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reference_feature = []\n",
    "for text in author_text_lower:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_self_reference = 0\n",
    "    else:\n",
    "        n_self_reference = self_reference_filter(text)/N\n",
    "    self_reference_feature.append(n_self_reference)\n",
    "\n",
    "    \n",
    "test_self_reference_feature = []\n",
    "for text in test_author_text_lower:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_self_reference = 0\n",
    "    else:\n",
    "        n_self_reference = self_reference_filter(text)/N\n",
    "    test_self_reference_feature.append(n_self_reference)\n",
    "    \n",
    "    \n",
    "self_reference_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "12bff158",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(self_reference_feature)\n",
    "X_self = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "89670df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_self_reference_feature)\n",
    "X_self_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c3960071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_self)\n",
    "X_self = scaler.transform(X_self)\n",
    "X_self_test = scaler.transform(X_self_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0273f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_self.npz', X_self)\n",
    "sparse.save_npz('data/X_self_test.npz', X_self_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ea355",
   "metadata": {},
   "source": [
    "### Internet Acronym Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71719912",
   "metadata": {},
   "source": [
    "Comparing every single word of each user and checking whether this word is contained in the acronym dictionary. The dictionary was made and edited in capital words: sometimes users write acronyms in non-capital format. For this reason, a non-case sensitive comparison has been made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26955558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acronyms = pd.read_csv(\"data/web_acronyms.csv\", encoding=\"utf8\", header=None)\n",
    "df_acronyms = df_acronyms[0].str.casefold()\n",
    "acronyms_1 = [acronym for acronym in df_acronyms]\n",
    "\n",
    "acronyms = []\n",
    "for acr in acronyms_1:\n",
    "    acronyms.append(''.join(filter(lambda x: x not in string.punctuation, acr)))\n",
    "acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "eb37c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acronyms_filter(text):\n",
    "    words = [word for word in text_split_filter(text)]\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        if word in acronyms:\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms_feature = []\n",
    "for text in author_text_lower:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_acronyms = 0\n",
    "    else:\n",
    "        n_acronyms = acronyms_filter(text)/N\n",
    "    acronyms_feature.append(n_acronyms)\n",
    "    \n",
    "\n",
    "test_acronyms_feature = []\n",
    "for text in test_author_text_lower:\n",
    "    N = len(text_split_filter(text))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_acronyms = 0\n",
    "    else:\n",
    "        n_acronyms = acronyms_filter(text)/N\n",
    "    test_acronyms_feature.append(n_acronyms)\n",
    "    \n",
    "acronyms_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "51174995",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(acronyms_feature)\n",
    "X_acronyms = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ace38d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_acronyms_feature)\n",
    "X_acronyms_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6d3b3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_acronyms)\n",
    "X_acronyms = scaler.transform(X_acronyms)\n",
    "X_acronyms_test = scaler.transform(X_acronyms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c54a3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_acronyms.npz', X_acronyms)\n",
    "sparse.save_npz('data/X_acronyms_test.npz', X_acronyms_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484eff4",
   "metadata": {},
   "source": [
    "### EMOTICONS FREQUENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "069b97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_emoticons = pd.read_csv(\"emoticons.csv\", encoding=\"utf8\", header=None)\n",
    "#emoticons = [emo for emo in df_emoticons]\n",
    "#emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "047901cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"data/emoticons.txt\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    emoticons = list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9acd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoticons_filter(text):\n",
    "    words = text_split_filter(text, no_punct=False)\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        for emo in emoticons:\n",
    "            if word in emo:\n",
    "                counter += 1\n",
    "    \n",
    "    return counter\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a245c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_feature = []\n",
    "for text in author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_emoticons = 0\n",
    "    else:\n",
    "        n_emoticons = emoticons_filter(text)/N\n",
    "    emoticons_feature.append(n_emoticons)\n",
    "    \n",
    "    \n",
    "test_emoticons_feature = []\n",
    "for text in test_author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_emoticons = 0\n",
    "    else:\n",
    "        n_emoticons = emoticons_filter(text)/N\n",
    "    test_emoticons_feature.append(n_emoticons)\n",
    "    \n",
    "emoticons_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eddf853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(emoticons_feature)\n",
    "X_emoticons = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "046dd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_emoticons_feature)\n",
    "X_emoticons_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a597754",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_emoticons)\n",
    "X_emoticons = scaler.transform(X_emoticons)\n",
    "X_emoticons_test = scaler.transform(X_emoticons_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56453621",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_emoticons.npz', X_emoticons)\n",
    "sparse.save_npz('data/X_emoticons_test.npz', X_emoticons_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4956e7",
   "metadata": {},
   "source": [
    "### Exclamation Mark Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "796dfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclamation_filter(text):\n",
    "    chars = text_split_filter(text, no_punct=False, char=True)\n",
    "    counter = 0\n",
    "    for char in chars:\n",
    "        if char=='!':\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclamation_feature = []\n",
    "for text in author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_exclamation = 0\n",
    "    else:\n",
    "        n_exclamation = exclamation_filter(text)/N\n",
    "    exclamation_feature.append(n_exclamation)\n",
    "    \n",
    "    \n",
    "test_exclamation_feature = []\n",
    "for text in test_author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_exclamation = 0\n",
    "    else:\n",
    "        n_exclamation = exclamation_filter(text)/N\n",
    "    test_exclamation_feature.append(n_exclamation)\n",
    "    \n",
    "exclamation_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e474d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(exclamation_feature)\n",
    "X_exclamation = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33fa8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_exclamation_feature)\n",
    "X_exclamation_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd50f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_exclamation)\n",
    "X_exclamation = scaler.transform(X_exclamation)\n",
    "X_exclamation_test = scaler.transform(X_exclamation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e93f353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_exclamation.npz', X_exclamation)\n",
    "sparse.save_npz('data/X_exclamation_test.npz', X_exclamation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e513f2",
   "metadata": {},
   "source": [
    "### Interrogation Mark Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f40f101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrogation_filter(text):\n",
    "    chars = text_split_filter(text, no_punct=False, char=True)\n",
    "    counter = 0\n",
    "    for char in chars:\n",
    "        if char=='?':\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf465a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrogation_feature = []\n",
    "for text in author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_interrogation = 0\n",
    "    else:\n",
    "        n_interrogation = interrogation_filter(text)/N\n",
    "    interrogation_feature.append(n_interrogation)\n",
    "    \n",
    "    \n",
    "    \n",
    "test_interrogation_feature = []\n",
    "for text in test_author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_interrogation = 0\n",
    "    else:\n",
    "        n_interrogation = interrogation_filter(text)/N\n",
    "    test_interrogation_feature.append(n_interrogation)\n",
    "    \n",
    "    \n",
    "interrogation_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5dc95061",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(interrogation_feature)\n",
    "X_interrogation = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc0da636",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_interrogation_feature)\n",
    "X_interrogation_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d9a891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_interrogation)\n",
    "X_interrogation = scaler.transform(X_interrogation)\n",
    "X_interrogation_test = scaler.transform(X_interrogation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4208463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_interrogation.npz', X_interrogation)\n",
    "sparse.save_npz('data/X_interrogation_test.npz', X_interrogation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925c687",
   "metadata": {},
   "source": [
    "### Quotation Mark Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "486c3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quotation_filter(text):\n",
    "    chars = text_split_filter(text, no_punct=False, char=True)\n",
    "    counter = 0\n",
    "    for char in chars:\n",
    "        if char=='\"':\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotation_feature = []\n",
    "for text in author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_quotation = 0\n",
    "    else:\n",
    "        n_quotation = quotation_filter(text)/N\n",
    "    quotation_feature.append(n_quotation)\n",
    "    \n",
    "    \n",
    "test_quotation_feature = []\n",
    "for text in test_author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_quotation = 0\n",
    "    else:\n",
    "        n_quotation = quotation_filter(text)/N\n",
    "    test_quotation_feature.append(n_quotation)\n",
    "    \n",
    "quotation_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b57dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(quotation_feature)\n",
    "X_quotation = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70a3709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_quotation_feature)\n",
    "X_quotation_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff18ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_quotation)\n",
    "X_quotation = scaler.transform(X_quotation)\n",
    "X_quotation_test = scaler.transform(X_quotation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c33b96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_quotation.npz', X_quotation)\n",
    "sparse.save_npz('data/X_quotation_test.npz', X_quotation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3b830",
   "metadata": {},
   "source": [
    "### Punctutation Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69ca9703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_list = string.punctuation\n",
    "punct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fa68775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_filter(text):\n",
    "    chars = text_split_filter(text, no_punct=False, char=True)\n",
    "    counter = 0\n",
    "    for char in chars:\n",
    "        if char in punct_list:\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b636405",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_feature = []\n",
    "for text in author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_punctuation = 0\n",
    "    else:\n",
    "        n_punctuation = punctuation_filter(text)/N\n",
    "    punctuation_feature.append(n_punctuation)\n",
    "    \n",
    "    \n",
    "test_punctuation_feature = []\n",
    "for text in test_author_text:\n",
    "    N = len(text_split_filter(text, no_punct=False, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_punctuation = 0\n",
    "    else:\n",
    "        n_punctuation = punctuation_filter(text)/N\n",
    "    test_punctuation_feature.append(n_punctuation)\n",
    "    \n",
    "punctuation_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5fb642eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(punctuation_feature)\n",
    "X_punctuation = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1848e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_punctuation_feature)\n",
    "X_punctuation_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74811609",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_punctuation)\n",
    "X_punctuation = scaler.transform(X_punctuation)\n",
    "X_punctuation_test = scaler.transform(X_punctuation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a4db044",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_punctuation.npz', X_punctuation)\n",
    "sparse.save_npz('data/X_punctuation_test.npz', X_punctuation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1522f",
   "metadata": {},
   "source": [
    "### Digits Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf391c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_list = [\n",
    "'0',\n",
    "'1',\n",
    "'2',\n",
    "'3',\n",
    "'4',\n",
    "'5',\n",
    "'6',\n",
    "'7',\n",
    "'8',\n",
    "'9'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "128966b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digits_filter(text):\n",
    "    chars = text_split_filter(text, char=True)\n",
    "    counter = 0\n",
    "    for char in chars:\n",
    "        if char in digits_list:\n",
    "            counter += 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb3f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_feature = []\n",
    "for text in author_text:\n",
    "    N = len(text_split_filter(text, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_digits = 0\n",
    "    else:\n",
    "        n_digits = digits_filter(text)/N\n",
    "    digits_feature.append(n_digits)\n",
    "    \n",
    "    \n",
    "test_digits_feature = []\n",
    "for text in test_author_text:\n",
    "    N = len(text_split_filter(text, char=True))\n",
    "    \n",
    "    if N == 0:\n",
    "        n_digits = 0\n",
    "    else:\n",
    "        n_digits = digits_filter(text)/N\n",
    "    test_digits_feature.append(n_digits)\n",
    "    \n",
    "digits_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5324bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(digits_feature)\n",
    "X_digits = sparse.csr_matrix(arr.reshape((5000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64fc4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.array(test_digits_feature)\n",
    "X_digits_test = sparse.csr_matrix(test_arr.reshape((15000,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31e31433",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_digits)\n",
    "X_digits = scaler.transform(X_digits)\n",
    "X_digits_test = scaler.transform(X_digits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8713bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/X_digits.npz', X_digits)\n",
    "sparse.save_npz('data/X_digits_test.npz', X_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9afa0",
   "metadata": {},
   "source": [
    "# Loading Preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650919fb",
   "metadata": {},
   "source": [
    "Creating target array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = target.gender\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fea27e",
   "metadata": {},
   "source": [
    "Creating Design Matrix from feature files, using a list of wanted features (in order to perform some tests, it is preferable to have the possibility to choose which features to use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f6d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix(features_all=False, feature_list=['subs', 'lembow', 'averagelength', 'maxlength', 'profanity', 'capitalwords', 'capitalletters', 'self', 'acronyms', 'emoticons', 'exclamation', 'interrogation', 'quotation', 'punctuation', 'digits']):\n",
    "    \"Function that generates the Design Matrix X from single features matrices/arrays\"\n",
    "    l = []\n",
    "    l_test = []\n",
    "    \n",
    "    if features_all == True:\n",
    "        feature_list_all = ['subs', 'lembow', 'averagelength', 'maxlength', 'profanity', 'capitalwords', 'capitalletters', 'self', 'acronyms', 'emoticons', 'exclamation', 'interrogation', 'quotation', 'punctuation', 'digits']\n",
    "        for feature in feature_list_all:\n",
    "            x = sparse.load_npz('data/X_'+str(feature)+'.npz')\n",
    "            x_test = sparse.load_npz('data/X_'+str(feature)+'_test.npz')\n",
    "            l.append(x)\n",
    "            l_test.append(x_test)\n",
    "        X = sparse.hstack(l)\n",
    "        X_test = sparse.hstack(l_test)\n",
    "    else:\n",
    "        for feature in feature_list:\n",
    "            x = sparse.load_npz('data/X_'+str(feature)+'.npz')\n",
    "            x\n",
    "            x_test = sparse.load_npz('data/X_'+str(feature)+'_test.npz')\n",
    "            l.append(x)\n",
    "            l_test.append(x_test)\n",
    "        X = sparse.hstack(l)\n",
    "        X_test = sparse.hstack(l_test)\n",
    "    \n",
    "    return X, X_test\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0befff99",
   "metadata": {},
   "source": [
    "Creating the Design Matrix. We can choose which features to include, so that different tests and options of Feature Selection can be performed at will (or if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db52ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x5228 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1510259 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = ['subs', 'lembow', 'averagelength', 'maxlength', 'profanity', 'capitalwords', 'capitalletters', 'self', 'acronyms', 'emoticons', 'exclamation', 'interrogation', 'quotation', 'punctuation', 'digits']#, 'averagelength', 'maxlength', 'profanity', 'capitalwords', 'capitalletters', 'self', 'acronyms', 'emoticons', 'exclamation', 'interrogation', 'quotation', 'punctuation', 'digits']\n",
    "X, X_test = generate_matrix(features_all=True, feature_list = feature_list)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d996901",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab86953",
   "metadata": {},
   "source": [
    "From the way the data has been processed, numerous features have been selected. The dataset dimensionality and feature correlations might hinder some models different from Neural Networks and Trees, that might then be able to perform better if a significative subset of the data is provided to them, rather than all of the variability. \n",
    "\n",
    "Hence, different feature techniques have been tried to improve performance and have been entagled in a pipeline in the model selection process (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7ddd6",
   "metadata": {},
   "source": [
    "A filtering feature selection method is applied. Keeping in mind that our input data is numerical and the output is categorical, the ANOVA score is applied. The number of features is given in the model selection process, in which ANOVA is part of the pipeline. Best scoring given for number of features of $\\sim$1500\n",
    "\n",
    "As a notice of work, different feature selection techniques have been tried. In particular Truncated SVD was tested as an alternative method that would keep sparsity untouched, but in the Model Selection/ Hyperparameters Selection, when included in the pipeline, even the best number for singular components to keep did not provide a performance on pair with ANOVA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a6e66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif #ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001d93d",
   "metadata": {},
   "source": [
    "Selecting which features to keep, once the optimal number $k$ is found during the Model Selection process (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5448372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=1520)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k=1520) # k is the number of features to be selected\n",
    "selector.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c7806",
   "metadata": {},
   "source": [
    "Transforming (selecting only relevant features) both Training & Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45f914ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selector.transform(X)\n",
    "X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343210a3",
   "metadata": {},
   "source": [
    "## Machine Learning --> Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23246159",
   "metadata": {},
   "source": [
    "Loading all the possible classifiers of choice in a dictionary, which contains the parameters as well (these are not directly used, are just personal reminders). The values provided in the code below are those found through model selection procedures in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f97e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "models = OrderedDict([\n",
    "          ('Knn', {\"model\" : KNeighborsClassifier(n_neighbors=6)\n",
    "                  ,\"best_hyper\" : {'n_neighbors' : 6}}),\n",
    "          ('NaiveBayes', {\"model\" : MultinomialNB(alpha=1.0240480961923848)\n",
    "                          ,\"best_hyper\" : {'alpha' : 1.81}}),\n",
    "    #Using SAGA optimizer as it is compatible with all types of regularization\n",
    "          ('LogisticRegression', {\"model\" : LogisticRegression(C = 2.694026845637584, penalty = 'elasticnet', solver = 'saga', max_iter = 10000, l1_ratio=0.0)\n",
    "                                 ,\"best_hyper\" : {'alpha' : 1.38}}),\n",
    "    \n",
    "          ('PolySVM', {\"model\" : SVC(kernel='poly', C=10, degree = 1, gamma = 'auto', probability=False)\n",
    "                      ,\"best_hyper\" : {'C' : 10\n",
    "                                      ,'degree' : 1\n",
    "                                      ,'gamma' : 'auto'}}),\n",
    "          ('RBFSVM', {\"model\" : SVC(kernel='rbf', C=6.222570836730231, gamma=0.051114334834401684, probability=True)\n",
    "                      ,\"best_hyper\" : {'C' : 6.222570836730231\n",
    "                                      ,'gamma' : 0.051114334834401684}}),\n",
    "    #Selecting Random Splitter since many features are present\n",
    "          ('ClassificationTree', {'model' : DecisionTreeClassifier(splitter='random', max_depth=2, min_samples_split=12, min_samples_leaf=6, max_features='sqrt')\n",
    "                                 ,'best_hyper' : {'max_depth' : 2\n",
    "                                                 ,'min_samples_split' : 4\n",
    "                                                 ,'min_samples_leaf' : 6\n",
    "                                                 ,'max_features' : 'auto'}}),\n",
    "          ('RandomForest', {'model' : RandomForestClassifier(max_depth=32, n_estimators=158, min_samples_split=2, min_samples_leaf=6, max_features='auto',n_jobs = -1)\n",
    "                           ,'best_hyper' : {'max_depth' : 45\n",
    "                                           ,'n_estimators' : 300\n",
    "                                           ,'min_samples_leaf' : 6\n",
    "                                           ,'min_samples_split' : 4\n",
    "                                           ,'max_features' : 'auto'}}),\n",
    "          ('MLP', {\"model\" : MLPClassifier(hidden_layer_sizes=(4), alpha=24.589178356713425, activation='relu',solver='lbfgs', max_iter=50000)\n",
    "                  ,\"best_hyper\" : {'hidden_layer_sizes' : (3)\n",
    "                                  ,'alpha' : 31.238476953907814}})\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209347e9",
   "metadata": {},
   "source": [
    "In order to provide a sample of (#layers,#neurons), defining a useful function for MLP hyperparameter optimization, which creates a random sample for the number of hidden layers and neurons. In this way, no manual selection is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4fcc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers_generator(n_hidden, max_neurons=8, min_neurons=1, samples_per_layer=3):\n",
    "    \"\"\"\n",
    "    Generate samples of layers for MLP\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    import random\n",
    "    hyper_layers = []\n",
    "    for n in range(1,n_hidden,1):\n",
    "        hyper_layers.extend(random.sample(list(itertools.product(range(min_neurons,max_neurons,1), repeat=n)), samples_per_layer))\n",
    "        \n",
    "    return hyper_layers\n",
    "    \n",
    "    #random.sample(list(itertools.product(range(1,20,1), repeat=random.randint(1,5))), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee63ca",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48895708",
   "metadata": {},
   "source": [
    "Defining the Cross-Validation strategy. Since classes are not balanced in the Training set, and considering that removal of data was not considered as an option given the fact that data is already limited in number of samples, a Stratified Cross-Validation is used: in this way, in each fold a proportionate number of samples from each class is used, so that the least possible bias is introduced in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b4d8adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d4117",
   "metadata": {},
   "source": [
    "### Hyperparameters Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f2b43",
   "metadata": {},
   "source": [
    "In the most promising models, a pipeline is introduced, in order to combine CV with Feature Selection, so as to provide the models the most optimal number of features through which they manage to generalize and correctly predict classes.\n",
    "\n",
    "Also, to speed up the process and maintain a good hyperparameter research accuracy, a HalvingGrid system is used, sometimes a RandomizedSearch is used to ballpark the hyperparameters values. Then, when a coarse idea has been obtained, these values are fine-tuned through a complete GridSearch to explore all the hyperparameters space and obtain an accurate estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d799c569",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30612869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "clf = models['Knn']['model']\n",
    "\n",
    "#After having tried on a larger scale, setting the research to \n",
    "#fine-research the best alpha value\n",
    "hyper = {}\n",
    "#hyper['C'] = np.logspace(-1.5, 3, 30)\n",
    "hyper['n_neighbors'] = range(2, 65)\n",
    "\n",
    "optimizer = GridSearchCV(clf, param_grid= hyper, n_jobs=-1, cv=cv, verbose=3, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))\n",
    "      \n",
    "clf.C = optimizer.best_params_['n_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e4ec9",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a97451",
   "metadata": {},
   "source": [
    "Naive Bayes algorithm gives best performance when paired with ANOVA feature selection (1400 features out of $\\sim$ 5400). In fact, Naive Bayes is one of the algorithms that works best after dimensionality reduction is applied, since a \"selection\" of the features is not natuarally incorporated as in models such as Trees and Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de46ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40000 candidates, totalling 200000 fits\n",
      "Best parameters for NaiveBayes are:\n",
      "{'anova__k': 1520, 'nb__alpha': 1.0240480961923848}\n",
      "Score: 0.8702\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif \n",
    "\n",
    "clf = models['NaiveBayes']['model']\n",
    "\n",
    "#After having tried on a larger scale, setting the research to \n",
    "#fine-research the best alpha value\n",
    "hyper = {}\n",
    "#hyper['nb__alpha'] = np.logspace(-1.5, 3, 30)\n",
    "hyper['nb__alpha'] = np.linspace(0.1, 3, 500)\n",
    "hyper['anova__k'] = np.arange(800, 1600, 10)\n",
    "\n",
    "pipe = Pipeline([('anova', SelectKBest(f_classif, k = 500)),\n",
    "                       ('nb', clf)])\n",
    "\n",
    "optimizer = GridSearchCV(pipe, param_grid= hyper, n_jobs=-1, cv=cv, verbose=3, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "print(\"Best parameters for\", str('NaiveBayes'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fdf340",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b736b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif \n",
    "\n",
    "clf = models['LogisticRegression']['model']\n",
    "\n",
    "#After having tried on a larger scale, setting the research to \n",
    "#fine-research the best alpha value\n",
    "hyper = {}\n",
    "#hyper['lr__C'] = np.logspace(-1.5, 3, 30)\n",
    "hyper['lr__C'] = np.linspace(0.01, 50, 150)\n",
    "hyper['lr__l1_ratio'] = np.linspace(0,1,20)\n",
    "hyper['anova__k'] = np.arange(1000, 2000, 20)\n",
    "#hyper['penalty'] = ['l1', 'l2']\n",
    "\n",
    "pipe = Pipeline([('anova', SelectKBest(f_classif, k = 500)),\n",
    "                       ('lr', clf)])\n",
    "\n",
    "optimizer = HalvingGridSearchCV(pipe, param_grid= hyper, n_jobs=-1, cv=cv, verbose=3, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a47c519",
   "metadata": {},
   "source": [
    "#### SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d233db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = models['PolySVM']['model']\n",
    "\n",
    "hyper = {}\n",
    "hyper['C'] = np.linspace(0.001, 10, 500)\n",
    "hyper['degree'] = range(1,8)\n",
    "#hyper['gamma'] = ['auto', 'scale']\n",
    "\n",
    "optimizer = RandomizedSearchCV(clf, param_distributions= hyper,n_iter = 60, cv=cv, verbose=3, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))\n",
    "      \n",
    "clf.C = optimizer.best_params_['C']\n",
    "clf.degree = optimizer.best_params_['degree']\n",
    "#clf.gamma = optimizer.best_params_['gamma']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3daede5",
   "metadata": {},
   "source": [
    "#### SVM RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8dfc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif \n",
    "\n",
    "#  if name == \"LogisticRegression\":\n",
    "#print('Starting', str(name), 'evaluation. Please wait...')\n",
    "clf = models['RBFSVM']['model']\n",
    "\n",
    "hyper = {}\n",
    "\n",
    "hyper['C'] = np.logspace(-3, 2, 200)\n",
    "hyper['gamma'] = np.logspace(-3, 2, 200)\n",
    "#hyper['anova__k'] = np.arange(500, 2000,50)\n",
    "\n",
    "#pipe = Pipeline([('anova', SelectKBest(f_classif, k=500)),('svm', clf)])\n",
    "\n",
    "optimizer = HalvingGridSearchCV(clf, param_grid = hyper, cv=cv, verbose=0, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))\n",
    "      \n",
    "clf.C = optimizer.best_params_['C']\n",
    "\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0102e37",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif \n",
    "#  if name == \"LogisticRegression\":\n",
    "#print('Starting', str(name), 'evaluation. Please wait...')\n",
    "clf = models['MLP']['model']\n",
    "\n",
    "hyper = {}\n",
    "#hyper['anova__k'] = np.arange(300, 3300,50)\n",
    "#hyper['hidden_layer_sizes'] = layers_generator(3, max_neurons=5,samples_per_layer=4)\n",
    "hyper['alpha'] = np.linspace(1,80, 500)\n",
    "\n",
    "#pipe = Pipeline([('anova', SelectKBest(f_classif, k=500)),('mlp', clf)])\n",
    "\n",
    "optimizer = GridSearchCV(clf, param_grid= hyper, cv=cv, verbose=3, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))\n",
    "      \n",
    "#clf.hidden_layer_sizes = optimizer.best_params_[hidden_layer_sizes']\n",
    "#clf.alpha = optimizer.best_params_['alpha']\n",
    "#clf.alpha = optimizer.best_params[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da696dd0",
   "metadata": {},
   "source": [
    "#### ClassificationTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2123b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = models['ClassificationTree']['model']\n",
    "hyper = {}\n",
    "hyper['max_depth'] = range(2, 150, 1)\n",
    "hyper['min_samples_split'] = np.arange(2,40)\n",
    "hyper['min_samples_leaf'] = np.arange(1,20)\n",
    "hyper['max_features'] = ['sqrt', 'auto', 'log2']\n",
    "      \n",
    "#Having numerous hyperparameters to check for, a Random search is done\n",
    "optimizer = HalvingGridSearchCV(clf, param_grid = hyper, cv=cv, n_jobs=-1, verbose=3, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))\n",
    "      \n",
    "clf.max_depth = optimizer.best_params_['max_depth']\n",
    "clf.min_samples_split = optimizer.best_params_['min_samples_split']\n",
    "clf.min_samples_leaf = optimizer.best_params_['min_samples_leaf'] \n",
    "clf.max_features = optimizer.best_params_['max_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de4f6b",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5502da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = models['RandomForest']['model']\n",
    "hyper = {}\n",
    "#hyper['n_estimators'] = range(50, 200, 6)\n",
    "hyper['max_depth'] = range(50, 150, 5)\n",
    "hyper['min_samples_split'] = np.arange(2,20)\n",
    "hyper['min_samples_leaf'] = np.arange(1,40)\n",
    "hyper['max_features'] = ['sqrt', 'auto', 'log2']\n",
    "      \n",
    "#Having numerous hyperparameters to check for, a Random search is done\n",
    "optimizer = HalvingGridSearchCV(clf, param_grid = hyper, cv=cv, n_jobs=-1, verbose=3, error_score=\"raise\")\n",
    "optimizer.fit(X, Y)\n",
    "\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer.best_params_)\n",
    "print('Score:', str(optimizer.best_score_))\n",
    "\n",
    "#clf.n_estimators = optimizer.best_params_['n_estimators']\n",
    "clf.max_depth = optimizer.best_params_['max_depth']\n",
    "clf.min_samples_split = optimizer.best_params_['min_samples_split']\n",
    "clf.min_samples_leaf = optimizer.best_params_['min_samples_leaf'] \n",
    "clf.max_features = optimizer.best_params_['max_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0d83e",
   "metadata": {},
   "source": [
    "## FINAL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32711689",
   "metadata": {},
   "source": [
    "Once hyperparameters are found, here the actual training is performed. In order to match Kaggle's AUC-ROC metric, a predict_proba method is used to evaluated probabilities for class attribution. The .csv file is formatted such that it matches the output required by the Kaggle's Competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c49d5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(test.author.unique(), columns=['author'])\n",
    "clf = models['NaiveBayes']['model']\n",
    "clf.fit(X, Y)\n",
    "pred = clf.predict_proba(X_test)\n",
    "prediction = result\n",
    "prediction['gender'] = np.array(pred)[:,1].tolist()\n",
    "prediction.to_csv('{0}\\{1}{2}'.format(\"Results\", str('NaiveBayes'), '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f5b28",
   "metadata": {},
   "source": [
    "**RESULT**: Naive Bayes applied with proper hyperparameter $\\alpha$ after ANOVA dimensionality reduction to 1480 features has been applied. Score in Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f2107",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857606cd",
   "metadata": {},
   "source": [
    "## 1.Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec8837",
   "metadata": {},
   "source": [
    "### Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b1fe557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = range(1000, 5000, 200)\n",
    "\n",
    "for x in n:\n",
    "    svd = TruncatedSVD(x)\n",
    "    svd.fit(X)\n",
    "\n",
    "#plt.plot(svd.explained_variance_ratio_)\n",
    "#plt.xlabel('Number of dimensions')\n",
    "#plt.ylabel('Explained variance ratio')\n",
    "#plt.show()\n",
    "\n",
    "    var_explained = svd.explained_variance_ratio_.sum()\n",
    "    print(var_explained)\n",
    "    \n",
    "    if var_explained>=0.95:\n",
    "        print ('This is the best number of parameters:', x)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "33ba18d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=1450)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components = 1450)\n",
    "svd.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "72c5feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = svd.transform(X)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5b7ea622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87427953724426\n"
     ]
    }
   ],
   "source": [
    "var_explained = svd.explained_variance_ratio_.sum()\n",
    "print(var_explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac289ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the explained variance ratio as a function of the number of dimensions\n",
    "plt.plot(svd.explained_variance_ratio_)\n",
    "plt.xlabel('Number of dimensions')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291aa8f",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908d176",
   "metadata": {},
   "source": [
    "### Try PCA for NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eedaaf1",
   "metadata": {},
   "source": [
    "Try making matrix dense and do PCA for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c544933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting delayedsparse\n",
      "  Downloading delayedsparse-0.2.4.tar.gz (18 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in d:\\anaconda3\\lib\\site-packages (from delayedsparse) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from delayedsparse) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in d:\\anaconda3\\lib\\site-packages (from delayedsparse) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.0->delayedsparse) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.0->delayedsparse) (2.2.0)\n",
      "Building wheels for collected packages: delayedsparse\n",
      "  Building wheel for delayedsparse (setup.py): started\n",
      "  Building wheel for delayedsparse (setup.py): finished with status 'done'\n",
      "  Created wheel for delayedsparse: filename=delayedsparse-0.2.4-py3-none-any.whl size=19763 sha256=b9f82dba24bf83ccb72c640a3a2cd08426711996ce85517e0bb7470fc8b41280\n",
      "  Stored in directory: c:\\users\\alber\\appdata\\local\\pip\\cache\\wheels\\74\\ca\\12\\3bc6f3a95c8890be326d46780e2d5b092a4b3ef0e55587cbdd\n",
      "Successfully built delayedsparse\n",
      "Installing collected packages: delayedsparse\n",
      "Successfully installed delayedsparse-0.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install delayedsparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f80ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1056)\n",
      "(1056,)\n",
      "(1056, 5228)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_pca = X.todense()\n",
    "pca = PCA(1056)\n",
    "\n",
    "pca.fit(X_pca)\n",
    "\n",
    "U = pca.transform(X_pca)\n",
    "S = pca.explained_variance_\n",
    "V = pca.components_\n",
    "\n",
    "print (U.shape)\n",
    "print (S.shape)\n",
    "print (V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cac0ef31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec95877760>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fee508e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ev_cumsum = np.cumsum(pca.explained_variance_)/(pca.explained_variance_).sum()\n",
    "ev_at90 = ev_cumsum[ev_cumsum<0.9].shape[0]\n",
    "print (ev_at90)\n",
    "\n",
    "plt.plot(ev_cumsum)\n",
    "plt.vlines(ev_at90, 0, 1, linestyles='dashed')\n",
    "plt.hlines(0.9, 0, 500, linestyles='dashed');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace855b3",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8e559",
   "metadata": {},
   "source": [
    "### On Categorical Features first, Numerical after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3e797",
   "metadata": {},
   "source": [
    "Since the Design Matrix is formed by multiple features, some categorical and some numerical, an attempt has been made to try and separate them to evaluate the hypothesis that models might behave best when dealing with just one kind of feature.\n",
    "\n",
    "In order to do so, a hyperparameter search is performed on the best performing set of feature ('Subreddits'), then trained with this specific hyperparameter on said feature and then, on the trained model, another hyperparameter search is applied with dimensionality reduction  (since Bag of Word is the most probable set of feature in which either redundancy or noise are found)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc96d38",
   "metadata": {},
   "source": [
    "### [TESTING] Uso prima i subreddit e poi faccio fine-tuning sulle altre feature ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bad89583",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_subs = ['subs']\n",
    "feat_rest = ['lembow', 'averagelength', 'maxlength', 'profanity', 'capitalwords', 'capitalletters', 'self', 'acronyms', 'emoticons', 'exclamation', 'interrogation', 'quotation', 'punctuation', 'digits']\n",
    "X_subs, X_test_subs = generate_matrix(features_all=False, feature_list = feat_subs)\n",
    "X_rest, X_test_rest = generate_matrix(features_all=False, feature_list = feat_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31a05fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "MultinomialNB(alpha=0.924553109823357)\n",
      "Fitting 5 folds for each of 27000 candidates, totalling 135000 fits\n",
      "Best parameters for LR are:\n",
      "{'anova__k': 1320, 'nb__alpha': 0.7643796948104811}\n",
      "Score: 0.737\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif \n",
    "\n",
    "\n",
    "\n",
    "clf = models['NaiveBayes']['model']\n",
    "\n",
    "#After having tried on a larger scale, setting the research to \n",
    "#fine-research the best alpha value\n",
    "hyper = {}\n",
    "hyper2 = {}\n",
    "#hyper['C'] = np.logspace(-1.5, 3, 30)\n",
    "hyper['alpha'] = np.logspace(-3, 2, 500)\n",
    "#hyper['anova__k'] = np.arange(1000, 1400, 10)\n",
    "\n",
    "#kbest = SelectKBest(f_classif) \n",
    "#pipe = Pipeline([('anova', SelectKBest(chi2, k = 500)), ('nb', clf)])\n",
    "\n",
    "optimizer1 = GridSearchCV(clf, param_grid= hyper, n_jobs=-1, cv=cv, verbose=3, error_score=\"raise\")\n",
    "optimizer1.fit(X_subs, Y)\n",
    "\n",
    "best_alpha1 = optimizer1.best_params_['alpha']\n",
    "best1 = optimizer1.best_estimator_\n",
    "print(best1)\n",
    "#DA PROVARE DOPO\n",
    "best1.fit(X_subs, Y)\n",
    "\n",
    "hyper2['nb__alpha'] = np.linspace(best_alpha1-abs(best_alpha1*0.2), best_alpha1 + abs(best_alpha1*0.2), 300) \n",
    "hyper2['anova__k'] = np.arange(800, 1700, 10)\n",
    "\n",
    "pipe = Pipeline([('anova', SelectKBest(f_classif, k = 500)),\n",
    "                       ('nb', best1)])\n",
    "optimizer2 = GridSearchCV(pipe, param_grid= hyper2, n_jobs=-1, cv=cv, verbose=3, error_score=\"raise\")\n",
    "optimizer2.fit(X_rest, Y)\n",
    "\n",
    "print(\"Best parameters for\", str('LR'), \"are:\")\n",
    "print(optimizer2.best_params_)\n",
    "print('Score:', str(optimizer2.best_score_))\n",
    "      \n",
    "#clf.C = optimizer.best_params_['alpha']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
